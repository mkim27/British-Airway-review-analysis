{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>place</th>\n",
       "      <th>content</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>seat_type</th>\n",
       "      <th>route</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>recommended</th>\n",
       "      <th>trip_verified</th>\n",
       "      <th>rating</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_staff_service</th>\n",
       "      <th>food_beverages</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service was mediocre at best</td>\n",
       "      <td>Gary Storer</td>\n",
       "      <td>03/10/2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Just returned from Chicago, flew out 10 days ...</td>\n",
       "      <td>A380</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Chicago to Manchester via Heathrow</td>\n",
       "      <td>01/10/2023</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA standards continue to decline</td>\n",
       "      <td>A Jensen</td>\n",
       "      <td>02/10/2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>BA standards continue to decline every time ...</td>\n",
       "      <td>A320</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>London Heathrow to Munich</td>\n",
       "      <td>01/09/2023</td>\n",
       "      <td>no</td>\n",
       "      <td>Verified</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>won the race to the bottom\"</td>\n",
       "      <td>John Rockett</td>\n",
       "      <td>02/10/2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Awful. Business class check in queue just as...</td>\n",
       "      <td>A320</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>Heathrow to Istanbul</td>\n",
       "      <td>01/09/2023</td>\n",
       "      <td>no</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             header        author        date           place  \\\n",
       "0      service was mediocre at best   Gary Storer  03/10/2023  United Kingdom   \n",
       "1  BA standards continue to decline      A Jensen  02/10/2023  United Kingdom   \n",
       "2      won the race to the bottom\"   John Rockett  02/10/2023  United Kingdom   \n",
       "\n",
       "                                             content aircraft  traveller_type  \\\n",
       "0   Just returned from Chicago, flew out 10 days ...     A380  Couple Leisure   \n",
       "1    BA standards continue to decline every time ...     A320        Business   \n",
       "2    Awful. Business class check in queue just as...     A320  Couple Leisure   \n",
       "\n",
       "        seat_type                               route  date_flown recommended  \\\n",
       "0   Economy Class  Chicago to Manchester via Heathrow  01/10/2023          no   \n",
       "1  Business Class           London Heathrow to Munich  01/09/2023          no   \n",
       "2  Business Class                Heathrow to Istanbul  01/09/2023          no   \n",
       "\n",
       "  trip_verified  rating  seat_comfort  cabin_staff_service  food_beverages  \\\n",
       "0  Not Verified     1.0           2.0                  3.0             1.0   \n",
       "1      Verified     1.0           2.0                  1.0             2.0   \n",
       "2  Not Verified     1.0           2.0                  3.0             2.0   \n",
       "\n",
       "   ground_service  value_for_money  entertainment  \n",
       "0             2.0                2            NaN  \n",
       "1             1.0                1            NaN  \n",
       "2             1.0                1            NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# References used:\n",
    "# NLTK basics: https://benalexkeen.com/basic-language-processing-with-nltk/\n",
    "# NLTK parts of speech (POS): https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html\n",
    "# NLTK tokenization, POS tagging: https://keremkargin.medium.com/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\n",
    "\n",
    "df = pd.read_csv('ba_reviews_clean.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Just', 'returned', 'Chicago', ',', 'flew', '10', 'days', 'ago', 'American', 'Airlines', 'absolutely', 'superb', 'every', 'way', ',', 'high', 'expectations', 'return', 'flight', 'BA', '.', 'What', 'disappointment', '.', 'The', 'Airbus', 'A380', 'may', 'nice', 'pilots', 'perspective', 'passenger', 'awful', '.', 'Very', 'uncomfortable', 'seats', ',', 'inflight', 'entertainment', 'flight', 'tracker', 'failed', 'work', 'throughout', 'flight', ',', 'inflight', 'meal', 'inedible', 'service', 'mediocre', 'best', '.', 'Our', 'short', 'flight', 'Heathrow', 'Manchester', 'much', 'improved', ',', 'welcoming', 'attentive', 'flight', 'staff', 'flight', 'even', 'arrived', 'early', '.', 'In', 'future', 'travel', 'one', 'American', 'carriers', '.']\n"
     ]
    }
   ],
   "source": [
    "example = df.loc[:,'content'][0]\n",
    "\n",
    "# stopwords: a set that holds common \"filler\" words like 'a', 'the', etc to filter out\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Just', 'RB'),\n",
       " ('returned', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('Chicago', 'NNP'),\n",
       " (',', ','),\n",
       " ('flew', 'VBD'),\n",
       " ('out', 'IN'),\n",
       " ('10', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " ('ago', 'RB'),\n",
       " ('on', 'IN'),\n",
       " ('American', 'NNP'),\n",
       " ('Airlines', 'NNP'),\n",
       " ('absolutely', 'RB'),\n",
       " ('superb', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('way', 'NN'),\n",
       " (',', ','),\n",
       " ('had', 'VBD'),\n",
       " ('high', 'JJ'),\n",
       " ('expectations', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('return', 'NN'),\n",
       " ('flight', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('BA', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " ('a', 'DT'),\n",
       " ('disappointment', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('Airbus', 'NNP'),\n",
       " ('A380', 'NNP'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('nice', 'JJ'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('pilots', 'NNS'),\n",
       " ('perspective', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('passenger', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('awful', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Very', 'RB'),\n",
       " ('uncomfortable', 'JJ'),\n",
       " ('seats', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('inflight', 'JJ'),\n",
       " ('entertainment', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('flight', 'NN'),\n",
       " ('tracker', 'NN'),\n",
       " ('failed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('throughout', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('flight', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('inflight', 'JJ'),\n",
       " ('meal', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('inedible', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('service', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('mediocre', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('best', 'JJS'),\n",
       " ('.', '.'),\n",
       " ('Our', 'PRP$'),\n",
       " ('short', 'JJ'),\n",
       " ('flight', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('Heathrow', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('Manchester', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('much', 'RB'),\n",
       " ('improved', 'VBN'),\n",
       " (',', ','),\n",
       " ('very', 'RB'),\n",
       " ('welcoming', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('attentive', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('flight', 'NN'),\n",
       " ('staff', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('flight', 'NN'),\n",
       " ('even', 'RB'),\n",
       " ('arrived', 'VBD'),\n",
       " ('early', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('future', 'JJ'),\n",
       " ('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('travel', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('American', 'JJ'),\n",
       " ('carriers', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos: part of speech. E.g, NN = noun\n",
    "tagged = nltk.pos_tag(word_tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes and turns all reviews into a giant string for tokenization \n",
    "all_reviews = df.loc[:,'content']\n",
    "all_reviews = ''.join(all_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "make custom arr of stop words for this specific british airways reviews dataset - flight, gate, airport, etc\n",
    "use stemming or lemmas to group plurals and singular versions of words into one word\n",
    "    then re-run word-tokenization\n",
    "    then regression/ML stuff to check which ratings correlate most closely to the overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = {'airplane', 'flight', 'gate', 'airport', 'plane', ',', '.'}\n",
    "custom_stop_words.update(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokenized = nltk.word_tokenize(all_reviews)\n",
    "clean_filtered = [w.lower() for w in cleaned_tokenized if not w.lower() in custom_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 25 mentioned words\n",
    "def getFrequentWords(tokenized):\n",
    "    freqs = defaultdict(int)\n",
    "    nouns = [word[0].lower() for word in tokenized if word[1] == 'NN']\n",
    "\n",
    "    for noun in nouns:\n",
    "        if noun in freqs:\n",
    "            freqs[noun] += 1\n",
    "        else:\n",
    "            freqs[noun] = 1\n",
    "\n",
    "    import operator\n",
    "    sorted_by_most_common = sorted(freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_by_most_common[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('service', 1123), ('ba', 1037), ('food', 950), ('seat', 863), ('class', 821), ('time', 820), ('business', 684), ('economy', 616), ('cabin', 590), ('staff', 567), ('crew', 546), ('heathrow', 447), ('london', 435), ('airline', 385), ('lounge', 367), ('aircraft', 365), ('experience', 342), ('club', 306), ('hour', 280), ('meal', 262), ('return', 258), ('world', 244), ('board', 241), ('choice', 222), ('way', 218)]\n"
     ]
    }
   ],
   "source": [
    "clean_tokens = nltk.pos_tag(clean_filtered)\n",
    "print(getFrequentWords(clean_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport airplan\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "w1 = (\"airport\")\n",
    "w2 = (\"airplane\")\n",
    "print( ps.stem(w1), ps.stem(w2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "airport\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize single word\n",
    "print(lemmatizer.lemmatize(\"airplanes\"))\n",
    "print(lemmatizer.lemmatize(\"airports\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 1123),\n",
       " ('ba', 1037),\n",
       " ('food', 950),\n",
       " ('seat', 863),\n",
       " ('class', 821),\n",
       " ('time', 820),\n",
       " ('business', 684),\n",
       " ('economy', 616),\n",
       " ('cabin', 590),\n",
       " ('staff', 567),\n",
       " ('crew', 546),\n",
       " ('heathrow', 447),\n",
       " ('london', 435),\n",
       " ('airline', 385),\n",
       " ('lounge', 367),\n",
       " ('aircraft', 365),\n",
       " ('experience', 342),\n",
       " ('club', 306),\n",
       " ('hour', 280),\n",
       " ('meal', 262),\n",
       " ('return', 258),\n",
       " ('world', 244),\n",
       " ('board', 241),\n",
       " ('choice', 222),\n",
       " ('way', 218)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lemma = []\n",
    "for word in clean_filtered:\n",
    "    clean_lemma.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "all_lemma = ''.join(clean_lemma)\n",
    "pos_lemma = nltk.pos_tag(clean_filtered)\n",
    "end_result = getFrequentWords(pos_lemma)\n",
    "end_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization didn't do much... at all... at least on the part about nouns. BUT doing this whole word tokenization in the first place showed that the most mentioned attributes of service were:\n",
    "    service\n",
    "    food\n",
    "    seat\n",
    "    class (business, economy)\n",
    "    staff\n",
    "    crew\n",
    "    experience\n",
    "\n",
    "which highlights the metrics of FOOD/BEVERAGES, ground service?, SEAT CLASS\n",
    "and things like ENTERTAINMENT were less thought about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'nltk_top_frequency.csv'\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for row in end_result:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(end_result)\n",
    "\n",
    "csv_file_path = 'nltk_top_frequency_pd.csv'\n",
    "df.to_csv(csv_file_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ba_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df[[\"rating\",\n",
    "              \"seat_comfort\",\n",
    "              \"cabin_staff_service\",\n",
    "              \"food_beverages\",\n",
    "              \"ground_service\",\n",
    "              \"value_for_money\",\n",
    "              \"entertainment\"]]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff = ratings.corr(method='pearson')\n",
    "corr_coeff.to_csv('rating_correlations.csv')\n",
    "corr_coeff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
